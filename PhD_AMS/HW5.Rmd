---
title: "HW5"
author: "Sheng Zhang"
date: "October 6, 2016"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 7.1
```{r 7.1, echo=TRUE}
z <- matrix(c(1,1,1,1,1,1,10,5,7,19,11,8),nrow=6,ncol=2)
y <- c(15,9,3,25,7,13)
beta <- solve(t(z)%*%z)%*%t(z)%*%y
y_hat <- z%*%beta
```

## 7.2
```{r 7.2, echo=TRUE}
z1 <- c(10,5,7,19,11,18)
z2 <- c(2,3,3,6,7,9)
y <- c(15,9,3,25,7,13)
z1_std <- (z1-mean(z1))/sd(z1)
z2_std <- (z2-mean(z2))/sd(z2)
y_std <- (y-mean(y))/sd(y)
model_std <- lm(y_std ~ z1_std + z2_std)
summary(model_std)
model <- lm(y ~ z1 + z2)
summary(model)
```

## 7.17
```{r 7.17, echo=TRUE}
forbes <- read.csv("./HW5-1.csv")
Sales <- forbes$Sales; Assets <- forbes$Assets
model <- lm(forbes$Profits ~ Sales + Assets)
summary(model)
# http://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/R/R5_Correlation-Regression/R5_Correlation-Regression7.html
par(mfrow = c(2, 2))
plot(model)
# leverage (to identify influential points)
# http://onlinestatbook.com/2/regression/influential.html
hatvalues(model)
newdata = data.frame(Sales=100, Assets=500)
predict.lm(model, newdata, interval="prediction",level=0.95)
```

a) The regression output is shown above.

b) The leverages are shown by the hatvalues function. None of the leverages is significantly greater than the other leverages.

c) As shown by the R output, the 95% prediction inverval asked for is [-1.546, 20.952].

d) As shown from summary(model), the coefficient for Assets has a t-value of 1.166 and an associated p-value of 0.2817, which is greater than our selected alpha of 0.05. This means that we fail to reject the null hypothesis that the coefficient is 0, suggesting we might want to drop the Assets variable from our regression model.


## 7.19
```{r 7.19, echo=TRUE}
library(MASS)
battery <- read.csv("./HW5 - 7.19.csv")
fit <- lm(log(y)~z1+z2+z3+z4+z5, data=battery)
# stepwise regression
step <- stepAIC(fit, direction="both")
step$anova # display results
# model comparison
fit2 <- lm(log(y)~z2+z4+z5, data=battery)
fit3 <- lm(log(y)~z2+z4, data=battery)
summary(fit2)
summary(fit3)
# regression diagnostics
par(mfrow = c(2, 2))
plot(fit2)
```

a) By comparing AIC and adjusted R^2 among different models, the model that includes z2, z4, and z5 perform the best when the dependent variable is ln(y).

b) The residual plot shows a little quadratic pattern, although the deviations from linearity and normality do not seem to be too pronounced. The QQ plot also indicates that the deviation from normality is small. Perhaps we could further test whether including interaction or higher order independent variables or transforming y in some other ways would help improve the model.

